---
title: "Introduction to Optimization"
subtitle: "Lecture 14"
author: "Vivek Srikrishnan"
course: "BEE 4750"
institution: "Cornell University"
date: "September 27, 2023"
format:
    revealjs:
        slide-number: c/t
        show-slide-number: all
        center-title-slide: true
        width: 1280
        height: 720
        transition: none
        toc: true
        toc-depth: 1
        toc-title: "Overview"
        history: false
        link-external-newwindow: true
        theme: ../sass/slides.scss
        footer: "[BEE 4750, Environmental Systems Analysis](https://viveks.me/environmental-systems-analysis)"
        template-partials:
            - title-slide.html
        menu:
            numbers: true
        html-math-method: mathjax
        include-in-header: mathjax-config.html
        date-format: long
        highlight-style: tango
        code-line-numbers: false
julia:
    exeflags: ["+1.10.4"]
execute:
    freeze: auto
---

```{julia}
#| echo: false
#| output: false

import Pkg
Pkg.activate(".")
Pkg.instantiate()
```

```{julia}
#| echo: false
#| output: false

using Measures
using Random
using Distributions
using Plots
using StatsPlots
using LaTeXStrings

Random.seed!(1)
```

# Review and Questions

## Last Class

- Decision models involve objectives and constraints.
- **Objective**: 
  - How are we assessing performance? (the **metric**)
  - Do we want to maximize or minimize?
- **Constraints**:
  - What are eligible decisions?
  - Engineering restrictions, performance or regulatory standards, etc.


## Wastewater Treatment Model

Last class, we looked at the following model for the treatment of wastewater from two point releases:

$$\begin{alignat}{3}
& \min_{E_1, E_2} &\quad  5000E_1^2 + 3000E_2^2 &  \\\\
& \text{subject to:} & 1000 E_1 &\geq 500 \\
& & 835E_1 + 1200E_2 &\geq 1459 \\
& & E_1, E_2 &\;\geq 0 \\
& & E_1, E_2 &\;\leq 1
\end{alignat}$$


## Solving This Problem

:::: {.columns}

::: {.column width=40%}
We can solve this graphically (see [the JuMP tutorial](../tutorials/julia-jump.html#visualizing-the-problem) for example code):

:::
::: {.column width=60%}

```{julia}
#| echo: false
#| fig-width: 6in

# define objective function
a = range(0, 1, step=0.05)
b = range(0, 1, step=0.05)
f(a, b) = 5000 * a.^2 + 3000 * b.^2
# plotting contours
contour(a,b,(a,b)->f(a,b), nlevels=15, 
  c=:heat, linewidth=5, colorbar = false, 
  contour_labels = true, grid = false, 
  right_margin=8mm, tickfontsize=16, legendfontsize=14, guidefontsize=16) 
xaxis!(L"E_1", ticks=0:0.1:1, 
  limits=(0, 1))
yaxis!(L"E_2", ticks=0:0.1:1, 
  limits=(0, 1))
plot!(size=(700, 600))

# plot constraints
vline!([0.5], color=:green, linewidth=3,
  label=false) # Equation 2
plot!(a, (1459 .- 835 .* a) ./ 1200, 
  color=:green, linewidth=3,
  label=false) # Equation 3
# plot feasible region
fa = a[a .>= 0.5]
fb = (1459 .- 835 .* a[a .>= 0.5])./1200
plot!(fa, fb, fillrange=1, 
  label="Feasible Region", opacity=0.4, 
  color=:green, legend=:bottomleft)
scatter!([0.5], [(1459 - 835 * 0.5) / 1200],
  markershape=:circle, color=:blue, 
  markersize=10, label="Optimum")
```
:::
::::

## The Solution

So the solution occurs at the intersection of the two constraints, where:

$$E_1 = 0.5, E_2 = 0.85$$

and the cost of this treatment plan is 

$$C(0.5, 0.85) = \$ 3417.$$


## Questions?

{{< include _poll-prompt.qmd >}}


# Optimization Models

## Components of an Optimization Model

  * **Objective Function**: The "target" function to be optimized.
  * **Decision Variables**: Variables which can be changed to affect objective.
  * **Constraints**: Limits on decision variable values.
  * **Feasible Solution**: Decision variable values satisfying constraints.
  * **Optimal Solution**: The "best" feasible solution or solutions (with respect to the objective)

## How Do We Solve An Optimization Problem?

{{< include _poll-prompt.qmd >}}

## Solution Approach 1: Trial and Error

What are some challenges to trial and error?

::: {.fragment .fade-in}

- Many possible solutions (infinitely many when a problem is continuous)
- Feasible region may not be intuitive
- How do we know when we've found an optimal solution?
:::

## Solution Approach 2: Generalized Search Algorithms

:::: {.columns}
::: {.column width=50%}

![Function with Multiple Minima](images/multiple-optima.svg)
:::

::: {.column width=50%}
Most search algorithms look for critical points to find candidate optima. Then the "best" of the critical points is the **global optimum**.
:::

::::


## Solution Approach 2: Generalized Search Algorithms

:::: {.columns}
::: {.column width=50%}

![Function with Multiple Minima](images/multiple-optima.svg)
:::

::: {.column width=50%}
Two common approaches:

- **Gradient-based methods**
- **Evolutionary algorithms**

:::

::::

## Generalized Search Algorithms

:::: {.columns}
::: {.column width=50%}
These methods work pretty well, but can:

- **require a lot of evaluations**;
- may get stuck at local optima;
- may not converge if step sizes aren't set correctly
:::

::: {.column width=50%}
![waiting model evaluation meme](figures/expensive-model-optimization.jpeg)
:::
::::

## Generalized Search Algorithms

:::: {.columns}
::: {.column width=50%}
These methods work pretty well, but can:

- require a lot of evaluations;
- **may get stuck at local optima**;
- may not converge if step sizes aren't set correctly
:::

::: {.column width=50%}
![waiting model evaluation meme](figures/gradient-descent-meme.jpeg)
:::
::::

## Generalized Search Algorithms

:::: {.columns}
::: {.column width=50%}
These methods work pretty well, but can:

- require a lot of evaluations;
- may get stuck at local optima;
- **may not converge if not tuned well**.
:::

::: {.column width=50%}
![waiting model evaluation meme](figures/stochastic-gradient-descent-meme.png){width=65%}
:::
::::

# Constrained Optimization

## Unconstrained Optimization

:::: {.columns}
::: {.column width=50%}

![Function with Multiple Minima](images/multiple-optima.svg)
:::

::: {.column width=50%}

Without constraints, our goal is to find extrema of the function.

Can do this using the structure of the objective (gradient) or through stochastic search (Monte Carlo).
:::
::::

## Constrained Optimization

:::: {.columns}
::: {.column width=50%}

![Function with Multiple Minima and a Constraint](images/multiple-optima-constrained.svg)
:::

::: {.column width=50%}
Now, notice the effect of a constraint!


For a constrained problem, we also have to look along the constraint to see if that creates a solution.
:::

::::

## Lagrange Multipliers

We can solve some constrained problems using Lagrange Multipliers!


Recall (maybe) that the Lagrange Multipliers method requires *equality* constraints. But we can easily create those with "dummy" variables.

## Using Equality Constraints

:::: {.columns}
::: {.column width=50%}

**Original Problem**


$$
\begin{aligned}
& \min &&f(x_1, x_2) \notag \\\\
& \text{subject to:} && x_1 \geq A \notag \\
& && x_2 \leq B \notag
\end{aligned}
$$
:::

::: {.column width=50%}

**With Dummy Variables**


$$
\begin{aligned}
& \min &&f(x_1, x_2) \notag \\\\
& \text{subject to:} && x_1 - S_1^2 = A \notag \\
& && x_2 + S_2^2 = B \notag
\end{aligned}
$$
:::
::::

## Using Lagrange Multipliers

Then the Lagrangian function becomes:


$$
H(\mathbf{x}, S_1, S_2, \lambda_1, \lambda_2) = f(\mathbf{x}) - \lambda_1(x_1 - S_1^2 - A) - \lambda_2(x_2 + S_2^2 - B)
$$


where $\lambda_1$, $\lambda_2$ are penalties for violating the constraints.


The $\lambda_i$ are the eponymous *Lagrange multipliers*.

## Using Lagrange Multipliers


Next step: locate possible optima where the partial derivatives of the Lagrangian are zero.

$$\frac{\partial H(\cdot)}{\partial \cdot} = 0$$

This is actually many equations, even though our original problem was low-dimensional, and can be slow to solve.

## Using Lagrange Multiplers

Despite these challenges, Lagrange Multiplers are at the core of many advanced search algorithms.



# Key Takeaways

## Key Takeaways

- We solve decision models through **optimization**.
- Decision models have a standard structure:
  - Decision Variables
  - Objective
  - Constraints
- **Goal**: find "best" solution with respect to the objective that is feasible.

## Key Takeaways

- Trial and error: not a great approach!
- Search algorithms: better!
- Lagrange Multipliers: Finally useful (for constrained optimization)!

# Upcoming Schedule

## Next Classes

**Friday**: Solving linear optimization models (linear programming)

**Monday**: Project proposal peer review.

**Wednesday**: Guest lecture by Diana Hackett (Mann librarian) on regulations research.

**Friday**: Lab on linear programming in Julia.
