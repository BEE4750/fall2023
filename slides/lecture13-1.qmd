---
title: "Deep Uncertainty"
subtitle: "Lecture 24"
author: "Vivek Srikrishnan"
course: "BEE 4750"
institution: "Cornell University"
date: "November 13, 2023"
format:
    revealjs:
        slide-number: c/t
        show-slide-number: all
        center-title-slide: true
        width: 1280
        height: 720
        transition: none
        toc: true
        toc-depth: 1
        toc-title: "Overview"
        history: false
        link-external-newwindow: true
        theme: ../sass/slides.scss
        footer: "[BEE 4750, Environmental Systems Analysis](https://viveks.me/environmental-systems-analysis)"
        template-partials:
            - title-slide.html
        menu:
            numbers: true
        html-math-method: mathjax
        include-in-header: mathjax-config.html
        date-format: long
julia:
    exeflags: ["+1.10.4"]
execute:
    freeze: auto
---

```{julia}
import Pkg
Pkg.activate(".")
Pkg.instantiate()
```

```{julia}
using Random
using XLSX
using DataFrames
using Distributions
using Plots
using LaTeXStrings
using Measures
```

# Review and Questions

## Simulation-Optimization

- General approach to decision-making
- Search for approximately "optimal" solutions by evaluating simulation model
- Relies on heuristics (no guarantees about optimality)
- Can be very sensitive to settings and details


# Uncertainty and Optimization

## Conceptual Assumptions of Optimization

**Most** optimization frameworks implicitly assume perfect specifications of:

- Model structures/Parameter values
- Decision alternatives
- Probabilities/distributions

## Reminder: Bifurcations

:::: {.columns}
::: {.column width=50%}
![Bifurcation Diagram](figures/bifurcation.png)
:::
::: {.column width=50%}
**Bifurcations** occur at thresholds when the qualitative behavior of a system changes.

These thresholds are often associated with a *stable* state equilibrium transitioning to an *unstable* one.
:::
::::

## Bifurcations and Misspecifications

```{julia}
#| layout-ncol: 2

x = 0:0.05:2.5
fin(x, q) = x.^q ./ (1 .+ x.^q)
fout(x, b) = b .* x

p1 = plot(x, fin(x, 2.5), color=:black, linewidth=5,legend=:topleft, label=" P Recycling", ylabel="P Flux", xlabel=L"$X_t$", title=L"$q=2.5$", tickfontsize=16, guidefontsize=18, legendfontsize=16, titlefontsize=26, palette=:tol_muted, framestyle=:origin, grid=:false)
plot!(x, fout(x, 0.4), linewidth=3, linestyle=:dash, label=" Outflow")
plot!(size=(600, 600), ylims=(0, 1))
quiver!([1], [0.35], quiver=([1], [0.4]), color=:red, linewidth=2)
quiver!([0.4], [0.12], quiver=([-0.125], [-0.05]), color=:red, linewidth=2)
quiver!([2.5], [0.97], quiver=([-0.125], [-0.05]), color=:red, linewidth=2)
scatter!([(0.67, 0.4 * 0.67)], markershape=:star5, color=:gold, markersize=16, label=:false)
display(p1)

p2 = plot(x, fin(x, 1), color=:black, linewidth=5,legend=:topleft, label=" P Recycling", ylabel="P Flux", xlabel=L"$X_t$", title=L"$q=1$", tickfontsize=16, guidefontsize=18, legendfontsize=16, titlefontsize=26, palette=:tol_muted, framestyle=:origin, grid=:false)
plot!(x, fout(x, 0.4), linewidth=3, linestyle=:dash, label=" Outflow")
plot!(size=(600, 600), ylims=(0, 1))
quiver!([0.4], [0.1], quiver=([1], [0.4]), color=:red, linewidth=2)
quiver!([2.3], [0.87], quiver=([-0.5], [-0.2]), color=:red, linewidth=2)
scatter!([(0.67, 0.4 * 0.67)], markershape=:star5, color=:gold, markersize=16, label=:false)
display(p2)
```

## A Relevant "Quote"

::: {.quote}
> It ain’t what you don’t know that gets you into trouble. It’s what you know for sure that just ain’t so. 

::: {.cite}
-- Often attributed to Mark Twain (apocryphal)
:::
:::

## How Do We Deal With Misspecification?

**If we know something about probabilities**: Monte Carlo or decision trees...

::: {.fragment .fade-in}
***What if we don't?***
:::

# Deep Uncertainty

## What Will CO~2~ Emissions Be In 2100?

:::: {.columns}
::: {.column width=50%}

```{julia}
emissions = DataFrame(XLSX.readtable(joinpath("data", "climate", "Global_Carbon_Budget_2022v1.0.xlsx"), "Global Carbon Budget", first_row=21)) # read in data
plot(emissions.Year, (emissions[:,2] .+ emissions[:,3]) .* 3.67, linewidth=3, label=:false, tickfontsize=16, guidefontsize=18, left_margin=5mm, bottom_margin=5mm)
xlabel!("Year")
ylabel!("Global CO₂ Emissions (Gt CO₂/yr)")
plot!(size=(600, 600))
```

:::

::: {.column width=50%}
How high do you think CO~2~ emissions be in 2100?
:::
::::

## How High Will CO~2~ Emissions Be In 2100?

{{< include _poll-prompt.qmd >}}

## Why Can't We Agree?

Future CO~2~ emissions are dependent on multiple factors which are difficult to forecast:

- economic output
- technological change
- policies and governance

## Deep Uncertainty

When there is no consensus probability for an uncertainty, we refer to it as a **deep uncertainty**.

## Another Relevant Quote!

::: {.quote}
> Reports that say that something hasn't happened are always interesting to me, because as we know, there are **known knowns**; there are things **we know we know**. We also know there are **known unknowns**; that is to say **we know there are some things we do not know**. But there are also **unknown unknowns** — the ones **we don't know we don't know**. And if one looks throughout the history of our country and other free countries, **it is the latter category that tends to be the difficult ones**.

::: {.cite}
-- Donald Rumsfeld, 2002 (emphasis mine)
:::
:::

## Translating the Word Salad

:::: {.columns}
::: {.column width=50%}
- **Known Knowns**: Certainty 
- **Known Unknowns**: "Shallow" Uncertainty
- **Unknown Unknowns**: "Deep" Uncertainty or ambiguity
:::
::: {.column width=50%}
![Mixed Dice Shapes](https://d26tpo4cm8sb6k.cloudfront.net/img/dice.jpg)
:::
::::

# The Ellsberg Paradox

## Deep Uncertainty and Decision-Making

"Standard" decision theory assumes people have consistent preferences in the presence of uncertainty, which reflects: 

- maximizing some estimation of "losses";
- under an evaluation of the probabilities of various outcomes.

::: {.fragment .fade-in}
**How do people make decisions under deep uncertainty?**
:::

## The Two-Urn Game

Consider two urns, each containing 100 balls. **Urn A** has 50 red, 50 black balls, **Urn B** is an unknown mix.

You are offered the following bets:
- **Bet 1A**: get $\$1$ if red ball drawn from Urn A, else $\$0$.
- **Bet 2A**: get $\$1$ if black ball drawn from Urn A, else $\$0$.
- **Bet 1B**: get $\$1$ if red ball drawn from Urn B, else $\$0$.
- **Bet 2B**: get $\$1$ if black ball drawn from Urn B, else $\$0$.

## Do You Prefer Bet 1A or 1B?

{{< include _poll-prompt.qmd >}}

## The Ellsberg Paradox (Part 1)

Participants in this experiment were indifferent between 1A and 2A, which is consistent with expected utility theory.

But they also strictly preferred 1A to 1B and 2A to 2B, even though there was no reason to expect that Urn 2 was stacked against them.

::: {.fragment .fade-in}
**Interpretation**: People have an aversion to deep uncertainty.
:::

## The One-Urn Game

Now there is only one urn, with *30 red balls* and *60 (black or yellow) balls* (in unknown proportions)

- **Bet A**: you win $\$100$ if you draw a red ball;
- **Bet B**: you win $\$100$ if you draw a black ball;
- **Bet C**: you win $\$100$ if you draw a red or yellow ball;
- **Bet D**: you win $\$100$ if you draw a black or yellow ball;

## Do You Prefer Bet A or B?

{{< include _poll-prompt.qmd >}}

## The One-Urn Game

Now there is only one urn, with *30 red balls* and *60 (black or yellow) balls* (in unknown proportions)

- **Bet A**: you win $\$100$ if you draw a red ball;
- **Bet B**: you win $\$100$ if you draw a black ball;
- **Bet C**: you win $\$100$ if you draw a red or yellow ball;
- **Bet D**: you win $\$100$ if you draw a black or yellow ball;

## Do You Prefer Bet C or D?

{{< include _poll-prompt.qmd >}}

## The Ellsberg Paradox (Part 2)

Ellsberg found subjects prefer Bet A to Bet B. This is consistent with the Two Urn game: deep uncertainty aversion.

::: {.fragment .fade-in}

Subjects also preferred Bet D to Bet C. ***Why is this strange?***
:::

# Key Takeaways

## Key Takeaways

- Misspecification is always a risk when developing a model, but can lead to major errors in the presence of nonlinear systems dynamics.
- Systems can also exhibit *deep* uncertainties.
- Deep uncertainty increases the risk of misspecification.
- Deep uncertainty can complicate decision-making by leading to inconsistent decisions.


# Upcoming Schedule

## Upcoming Schedule

**Wednesday/Friday**: How do we analyze decisions when there is a risk of model misspecification or deep uncertainty?

**After Thanksgiving**: No class, will schedule 10-minute meetings with teams during class time the week after Thanksgiving to check on project progress. ***Attendance is required during your meeting***.

## Assessments

**Lab 4**: Due Friday

**Project**: Make sure you check what's due when!
