{
  "hash": "3495be537301ea34820b444ffecc753f",
  "result": {
    "engine": "julia",
    "markdown": "---\ntitle: \"BEE 4750 Lab 4: Simulation-Optimization\"\nformat:\n    html:        \n        warning: true\n        error: true\n        mermaid:\n            theme: forest\n    ipynb:\n        warning: true\n        error: true\n        code-annotation: below\nengine: julia\nformat-links: []\n---\n\n::: {.content-visible when-format=\"ipynb\"}\n**Name**:\n\n**ID**:\n:::\n\n::: {.callout-important icon=\"false\"}\n### Due Date\n\nFriday, 11/17/23, 9:00pm\n:::\n\n::: {.content-visible when-format=\"html\"}\n::: callout-caution\nIf you are enrolled in the course, make sure that you use the GitHub Classroom link provided in Ed Discussion, or you may not be able to get help if you run into problems.\n\nOtherwise, you can [find the Github repository here](https://github.com/BEE4750/lab04).\n:::\n:::\n\n## Setup\n\nThe following code should go at the top of most Julia scripts; it will load the local package environment and install any needed packages. You will see this often and shouldn't need to touch it.\n\n::: {#2 .cell execution_count=1}\n``` {.julia .cell-code}\nimport Pkg\nPkg.activate(\".\")\nPkg.instantiate()\n```\n:::\n\n\n\n::: {#4 .cell execution_count=1}\n``` {.julia .cell-code}\nusing Random # for random seeds\nusing Distributions # statistical distribution interface\nusing Roots # find zeros of functions\nusing Metaheuristics # search algorithms\nusing Plots # plotting\n```\n:::\n\n\n\n::: {.cell .markdown}\n## Overview\n\nIn this lab, you will experiment with simulation-optimization with the shallow lake problem. The goal of this experimentation is to get an understanding of how to work with simulation-optimization methods and the impact of some choices involved in using these methods.\n\nFree free to delete some of the illustrative cells and code blocks in your notebook as you go through and solve the lab problems...this might help reduce some potential confusion while grading about what your answer is.\n:::\n\n::: {.cell .markdown}\n## Introduction\n\nDue to ongoing economic activity, a town emits phosphorous into a shallow lake (with a concentration of $a_t$), which also receives non-point source runoff (concentration $y_t$) from the surrounding area. The concentration of the lake at time $t+1$ is given by\n$$X_{t+1} = X_t + a_t + y_t + \\frac{X_t^q}{1+X_t^q} - bX_t,$$\n\nwhere:\n\n| Parameter | Value |\n| :------: | :------ |\n| $a_t$ | point-source phosphorous concentration from the town |\n| $y_t$ | non-point-source phosphorous concentration |\n| $q$ | rate at which phosphorous is recycled from sediment |\n| $b$| rate at which phosphorous leaves the lake |\n\nand $X_0 = 0$, $y_t \\sim LogNormal(\\log(0.03), 0.25)$, $q=2.5$, and $b=0.4$.\n\nThe goal of the optimization is to maximize the town's average phosphorous concentration releases (as a proxy of economic activity): $\\max \\sum_{t=1}^T a_t / T$ over a 100-year period. We have decided (initially) that an acceptable solution is one which will result in the lake eutrophying no more than 10% of the time.\n\nThe non-point source samples can be sampled using the following code block:\n:::\n\n::: {#6 .cell execution_count=1}\n``` {.julia .cell-code}\nRandom.seed!(1)\n\nT = 100 # length of simualtion\nn_samples = 1_000 # replace with number of samples if you experiment\n\nP_distribution = LogNormal(log(0.03), 0.25)\ny = rand(P_distribution, (T, n_samples)) # sample a T x n_samples matrix\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n100√ó1000 Matrix{Float64}:\n 0.0304681  0.0285057  0.0355363  ‚Ä¶  0.0224551  0.0316383  0.0369517\n 0.0321624  0.0278158  0.0217135     0.0382034  0.0232944  0.0267399\n 0.0258482  0.0234287  0.0283147     0.0202217  0.048585   0.0363454\n 0.030352   0.0337715  0.0266175     0.0309283  0.024296   0.047442\n 0.0393559  0.0340622  0.0448934     0.0293712  0.028231   0.0344968\n 0.0202278  0.0310688  0.0181462  ‚Ä¶  0.0265555  0.0235964  0.0303528\n 0.031349   0.0322554  0.0424454     0.0317823  0.0295711  0.0227756\n 0.0372459  0.0364071  0.0384649     0.0345461  0.0332709  0.0479824\n 0.0149338  0.0370531  0.0268489     0.0220696  0.0485319  0.0183377\n 0.0186938  0.0279637  0.0409538     0.044512   0.0279454  0.0246053\n ‚ãÆ                                ‚ã±                        \n 0.0361638  0.0187471  0.028957      0.020726   0.0296569  0.0270623\n 0.0263427  0.0416441  0.0368316     0.0308642  0.0384248  0.0382549\n 0.0281714  0.0264096  0.0337333     0.0291933  0.024468   0.0279627\n 0.0406918  0.0260099  0.043256      0.033575   0.0272049  0.0289137\n 0.0385466  0.0400145  0.0236115  ‚Ä¶  0.025868   0.0170059  0.0215322\n 0.0338512  0.0339457  0.0552938     0.0249511  0.0597814  0.0231636\n 0.0406508  0.0289635  0.0332456     0.0477649  0.0281822  0.0362461\n 0.0383625  0.0275352  0.0456234     0.0262813  0.0287315  0.0254019\n 0.0278233  0.023814   0.0295692     0.0245641  0.042677   0.029458\n```\n:::\n:::\n\n\n\nWe write the lake model as a function:\n\n::: {#8 .cell execution_count=1}\n``` {.julia .cell-code}\n# lake function model\n# inputs:\n#   a: vector of point-source releases (to be optimized)\n#   y: randomly-sampled non-point sources\n#   q: lake phosphorous recycling rate\n#   b: phosphorous outflow rate\n# \n# returns:\n#   series of lake phosphorous concentrations\nfunction lake(a, y, q, b, T)\n    X = zeros(T+1, size(y, 2))\n    # calculate states\n    for t = 1:T\n        X[t+1, :] = X[t, :] .+ a[t] .+ y[t, :] .+ (X[t, :].^q./(1 .+ X[t, :].^q)) .- b.*X[t, :]\n    end\n    return X\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nlake (generic function with 1 method)\n```\n:::\n:::\n\n\n\n::: {.cell .markdown}\nHowever, this isn't sufficient on its own! `Metaheuristics.jl` (and most simulation-optimization packages) require the use of a *wrapper* function, which accepts as inputs both parameters to be optimized (in this case, point-source releases `a`) and parameters which will be fixed (the others; see below for how to incorporate these into the syntax) and returns the required information for the optimization procedure.\n\n`Metaheuristics.jl` wants its optimizing wrapper function to return (in order):\n\n* the objective(s) (in this case, the mean of `a`, $\\sum_t a_t / T$), \n* a vector of the degrees to which the solution fails to achieve any inequality constraints (positive values indicate a larger failure, values below zero are considered acceptable)\n* a vector of the degrees to which the solution fails to achieve any equality constraints (only values of zero indicate success), which in this case is not relevant, so we just return `[0.0]`.\n\n:::\n\n::: {#10 .cell execution_count=1}\n``` {.julia .cell-code}\n# function producing optimization outputs\n# inputs:\n#   a: vector of point-source releases (to be optimized)\n#   y: randomly-sampled non-point sources\n#   q: lake phosphorous recycling rate\n#   b: phosphorous outflow rate\n# \n# returns:\n#   - objective: mean value of point-source releases\n#   - inequality constraint failure vector\n#   - equality constraint failure vector (in this case, always [0.0])\nfunction lake_opt(a, y, q, b, T, Xcrit)\n    X = lake(a, y, q, b, T)\n    # calculate exceedance of critical value\n    Pexceed = sum(X[T+1, :] .> Xcrit) / size(X, 2)\n    failconst = [Pexceed - 0.1] # replace 0.1 if you experiment with the failure probability\n    return mean(a), failconst, [0.0]\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nlake_opt (generic function with 1 method)\n```\n:::\n:::\n\n\n\n::: {.cell .markdown}\nTo optimize using DE (differential evolution), use the following syntax:\n\n```julia\nresults = optimize(f, bounds, DE(options=Options(f_calls_limit=max_evals)))\n```\n\nwhere `bounds` is a `Matrix` of lower bounds (first row) and upper bounds (last row), and `max_evals` is an integer for the maximum number of evaluations. \n\n* For example, to set bounds for all decision variables between 0 and 0.5, you can use \n```julia\nbounds = [zeros(T) 0.5ones(T)]'\n```\n* Increasing `max_evals` can help you find a better solution, but at a larger computational expense.\n* You can use an anonymous function to fix values for non-optimized parameters, *e.g.*\n```julia\ny = ...\nq = ...\nb = ...\nT = ...\nXcrit = ...\nresults = optimize(a -> lake_opt(a, y, q, b, t, Xcrit), bounds, DE(options=Options(f_calls_limit=max_evals)))\n```\n\n\nThen to get the approximated minimum value:\n\n```julia\nfx = minimum(result)\n```\n\nand the approximated minimizing value:\n\n```julia\nx = minimizer(result)\n```\n\nThe last piece is to get the critical value (to identify failures), which we can do using `Roots.jl`, which finds zeros of functions:\n:::\n\n::: {#12 .cell execution_count=1}\n``` {.julia .cell-code}\n# define a function whose zeros are the critical values\nP_flux(x) = (x^q/(1+x^q)) - b*x\n# use Roots.find_zero() to find the non-eutrophication and non-zero critical value; we know from visual inspection in class that this is bounded between 0.1 and 1.5.\nXcrit = find_zero(P_flux, (0.1, 1.5))\n```\n\n::: {.cell-output .cell-output-error}\n```\nUndefVarError: UndefVarError(:q, Main.Notebook)\nUndefVarError: `q` not defined in `Main.Notebook`\nSuggestion: check for spelling errors or missing imports.\nStacktrace:\n  [1] P_flux(x::Float64)\n    @ Main.Notebook ~/Teaching/BEE4750/fall2023/labs/lab04/lab04.qmd:194\n  [2] (::Roots.Callable_Function{Val{1}, Val{false}, typeof(P_flux), Nothing})(x::Float64)\n    @ Roots ~/.julia/packages/Roots/nTKv3/src/functions.jl:29\n  [3] init_state(M::Bisection, F::Roots.Callable_Function{Val{1}, Val{false}, typeof(P_flux), Nothing}, x::Tuple{Float64, Float64})\n    @ Roots ~/.julia/packages/Roots/nTKv3/src/Bracketing/bracketing.jl:5\n  [4] init(ùë≠ùëø::ZeroProblem{typeof(P_flux), Tuple{Float64, Float64}}, M::Bisection, p‚Ä≤::Nothing; p::Nothing, verbose::Bool, tracks::Roots.NullTracks, kwargs::@Kwargs{})\n    @ Roots ~/.julia/packages/Roots/nTKv3/src/find_zero.jl:299\n  [5] init\n    @ ~/.julia/packages/Roots/nTKv3/src/find_zero.jl:289 [inlined]\n  [6] solve(ùë≠ùëø::ZeroProblem{typeof(P_flux), Tuple{Float64, Float64}}, M::Bisection, p::Nothing; verbose::Bool, kwargs::@Kwargs{tracks::Roots.NullTracks})\n    @ Roots ~/.julia/packages/Roots/nTKv3/src/find_zero.jl:491\n  [7] find_zero(f::Function, x0::Tuple{Float64, Float64}, M::Bisection, p‚Ä≤::Nothing; p::Nothing, verbose::Bool, tracks::Roots.NullTracks, kwargs::@Kwargs{})\n    @ Roots ~/.julia/packages/Roots/nTKv3/src/find_zero.jl:220\n  [8] find_zero (repeats 2 times)\n    @ ~/.julia/packages/Roots/nTKv3/src/find_zero.jl:210 [inlined]\n  [9] find_zero(f::Function, x0::Tuple{Float64, Float64})\n    @ Roots ~/.julia/packages/Roots/nTKv3/src/find_zero.jl:243\n [10] top-level scope\n    @ ~/Teaching/BEE4750/fall2023/labs/lab04/lab04.qmd:196\n```\n:::\n:::\n\n\n\n\n## Problems\n\n### Problem 1 (2 points)\n\nUsing the default setup above, find the approximate optimum value. What is the value of the objective function, and how many failures (you can evaluate the `lake` function using your solution to find how many end-values are above the critical value).\n\n### Problem 2 (5 points)\n\n::: {.cell .markdown}\nFeel free to experiment with some of the degrees of freedom in finding the optimum value. For example:\n\n* What failure probability are you using to characterize acceptable solutions?\n* How many Monte Carlo samples are you using?\n* What bounds are you searching over for the releases?\n* How many function evaluations are you using for the search?\n* What is the impact of different [`Metaheuristics.jl` algorithms](https://docs.juliahub.com/Metaheuristics/aJ70z/3.2.12/algorithms/)?\n\nNote that you might want to modify some of these together: for example, lower acceptable failure probabilities often require more function evaluations to find acceptable values, and more Monte Carlo samples increase computational expense, so fewer function evaluations may be completed in the same time.\n\nProvide a description of what you've modified and why. What was the new solution that you found? Does it satisfy the constraints?\n:::\n\n### Problem 3 (3 points)\n\nWhat did you learn about the use of these methods? Compare with your experience with linear programming from earlier in the semester.\n\n\n## References\n\nPut any consulted sources here, including classmates you worked with/who helped you.\n\n",
    "supporting": [
      "lab04_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}